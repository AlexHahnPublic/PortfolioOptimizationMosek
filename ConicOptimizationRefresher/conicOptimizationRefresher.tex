\documentclass{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath,amssymb}
\usepackage{parskip}
\usepackage{graphicx}

% Margins
\usepackage[top=2.5cm, left=3cm, right=3cm, bottom=4.0cm]{geometry}
% Colour table cells
\usepackage[table]{xcolor}

% Get larger line spacing in table
\newcommand{\tablespace}{\\[1.25mm]}
\newcommand\Tstrut{\rule{0pt}{2.6ex}}         % = `top' strut
\newcommand\tstrut{\rule{0pt}{2.0ex}}         % = `top' strut
\newcommand\Bstrut{\rule[-0.9ex]{0pt}{0pt}}   % = `bottom' strut

%%%%%%%%%%%%%%%%%
%     Title     %
%%%%%%%%%%%%%%%%%
\title{Conic Optimization Refresher}
\author{Alex Hahn \\ from mosek cookbook}
\date{\today}

\begin{document}
\maketitle

%%%%%%%%%%%%%%%%%
%   intro formulation   %
%%%%%%%%%%%%%%%%%
\section{Types of Cones}
Conic optimization is a class of convex optimization problems. The geneneral form of a conic optimization problem is:

$$\text{maximize } \mathbf{c}^T\mathbf{x}$$
$$\text{subject to } \mathbf{Ax} + \mathbf{b} \in \mathcal{K} $$
where $\mathcal{K}$ is a product of the following basic types of cones:

\begin{itemize}
\item{\textbf{Linear cone:}}
\end{itemize}
$$\mathbb{R}, \mathbb{R}^n_+, {0}$$

\begin{itemize}
\item{\textbf{Quadratic cone and rotated quadratic cone:}}
\end{itemize}
The quadratic cone is the set
$$\mathcal{Q}^n = \left\{ x \in \mathbb{R} \bigg| x_1 \geq \sqrt{x_2^2 +\cdots+ x_n^2}\right\}$$
The rotated quadratic cone is the set
$$\mathcal{Q}_r^n = \left\{ x \in \mathbb{R} \bigg|2x_1x_2\geq x_3^2+\cdots + x_n^2, x_1, x_2\geq 0\right\}$$

Together the union of these two cones covers the class of SOCO (second-order cone optimization)
problems which includes all QO (quadratic optimization) and QCQO (quadratically constrained
quadratic optimization) problems as well.

\begin{itemize}
\item{\textbf{Primal power cone:}}
\end{itemize}

$$\mathcal{P}^{\alpha, 1-\alpha}_n = \left\{ x \in \mathcal{R}^n\bigg|x_1^\alpha x_2^{1-\alpha}\geq\sqrt{x_3^2+\cdots+x_n^2},x_1,x_2 \geq 0\right\}$$

\begin{itemize}
\item{\textbf{Primal exponential cone:}}
\end{itemize}

$$K_{\text{exp}} = \left\{ x \in \mathcal{R}^3\bigg|x_1\geq x_2\text{exp}\left(\frac{x_3}{x_2}\right),x_1,x_2 \geq 0\right\}$$

\begin{itemize}
\item{\textbf{Semidefinite cone:}}
\end{itemize}

$$\mathcal{S}^n_+=\{X \in \mathbb{R}^{n\times n}| X\text{ is symmetric positive semidefinite}$$

Semidefinite cones model SDO problems.

Each of these cones allow formulating different types of convex constraints.

\section{Selection of Conic Constraints}

Examples of real world constraints (financial)and how to convert them to conic form.

\subsection{Maximum function}

Model the maximum constraint max($x_1, x_2, ... , x_n)\leq c$ using n linear constraints introduces with an auxiliary variable $t$:

\begin{align}
  \begin{split}
    t &\leq c, \\
    t &\geq x_1, \\
    &\vdots \\
    t &\geq x_n.
  \end{split}
\end{align}

For example we can write the constraints max$(x_i,0)\leq c_i, 1,...,n$ as
$$\mathbf{t} \leq \mathbf{c}, \mathbf{t}\geq \mathbf{x}, \mathbf{t}\geq \mathbf{0},$$
where \textbf{t} is an $n$-dimensional vector.

\subsection{Positive and negative part}

A special case of modeling the maximum function is to model the positive part $x^+$ and the negative part $x^-$ of a variable $x$.
We define these as $x^+=\text{max}(x,0)$ and $x^-=\text{max}(-x,0)$. Model them explicitly with the above methodology and
the inequatlities $x^+=\text{max}(x,0)$ and $x^-=\text{max}(-x,0)$, or implicitly with the constraints:


$$x = x^+ - x^-,$$
$$x^+, x^- \geq 0.$$

Note, there is still a degree of freedom in both the implicit and explicit magnitudes of $x^+$ and $x^-$. In the
explicit case we have inequalities and in the implicit case only the difference of the variables is constrained.
Ultimately it is possible for both $x^+$ and $x^-$ to be positive, allowing optimal solutions where $x^+ = \text{max}(x,0)$
and $x^-1=\text{max}(-x,0)$ does not hold.

Theoretically we can introduce a complimentarity contraint $x^+x^-=0$ (or $\langle\textbf{x}^+,\textbf{x}^-\rangle=0$)
but that is non-convex/ can't be modeled. There are two workarounds to ensure that $x^+ = \text{max}(x,0)$
and $x^-1=\text{max}(-x,0)$ hold the optimal solution: 1) penalize the magnitude of the two solutions, so if both
are positive in any one solution, the solver could always improve the objective by reducing them until either one
becomes zero. 2) formulate a mixed integer problem.

\subsection{Absolute value}
We can model the absolute value constraint $|x| \leq c$ by using the maximum function observing that
$|x|=\text{max}(x,-x)$:
$$-c\leq x\leq c$$

Or you could use a quadratic cone:
$$(c,x)\in \mathcal{Q}^2$$

\subsection{Sum of largest elements}

The sum of the m largest elements of a vector $\mathbf{x}$ is the optimal solution of the LO problem:
$$\text{maximize } \mathbf{x}^T\mathbf{z}$$
$$\text{subject to } \mathbf{1}^T\mathbf{z}=m,$$
$$\mathbf{0}\leq\mathbf{z}\leq\mathbf{1}$$

Here \textbf{x} cannot be a variable as this would result in a nonlinear objective. Looking at the dual of
the problem:
$$\text{minimize } mt + \mathbf{1}^T\mathbf{u}$$
$$\text{subject to } \mathbf{u} + t \geq \mathbf{x},$$
$$\mathbf{u} \geq 0.$$

This is the same problem as min$_t$ $mt + \sum_i\text{max}(0,x_i-t)$, in which $x$ can be a variable and thus optimized.

\subsection{Linear combination of largest elements}

Selecting \textbf{z} tot have an upper bound $\mathbf{c}\geq\mathbf{0}$, and a real number
$0\leq b \leq c_\text{sum}$ instead of integer $m$, where $c_\text{sum}=\sum_ic_i$:
$$\text{maxmize } \mathbf{x}^T\mathbf{z}$$
$$\text{subject to } \mathbf{1}^T\mathbf{Z} = c_\text{sum} - b,$$
$$\mathbf{0}\leq\mathbf{z}\leq\mathbf{c}.$$

This has the optimal objective $c^\text{frac}x_{ib} + \sum_{i>i_b}c_ix_i$ where $i_b$ is such that
$\sum_{i=1}^{i_b-1}c_i<b\leq\sum^{i_b}_{i=1}c_i$, and $c_{i_b}^\text{frac}=\sum^{i_b}_{i=1}c_i-b<c_{i_b}.$
The dual of this problem:

$$\text{minimize } (c_\text{sum}-b)t+\mathbf{c}^T\mathbf{u}$$
$$\text{subject to } \mathbf{u}+t\geq\mathbf{x},$$
$$\mathbf{u}\geq\mathbf{0}.$$

which is the same as $\text{min}_t(c_\text{sum}-b)t+\sum_ic_i\text{max}(0,x_i-t)$.

\subsection{Manhattan Norm}
Let $\mathbf{x}\in \mathbb{R}^n$ with the standard 1-norm / Manhattan norm. A
1-norm constrant $||\mathbf{x}||_1\leq c||$ can be formed by modeling the
absolute value for each coordinate:
$$\mathbf{z}\leq x\leq \mathbf{z}, \sum_{i=1}^nz_i=c,$$
where \textbf{z} is an auxilliary variable

\subsection{Euclidean Norm}
Let $\mathbf{x} \in \mathbb{R}^n$ with the standard 2-norm / Euclidean norm
definition $||\mathbf{x}||_2 = \sqrt{x_1^2+\cdots+x_n^2}$. A Euclidean
norm constraint $||\mathbf{x}||_2\leq c$ can be modelled using a quadratic
cone:
$$(c,\mathbf{x}) \in \mathcal{Q}^{n+1}$$

\subsection{Squared Euclidean Norm}
Let $\mathbf{x} \in \mathbb{R}^n$ take the square of the Euclidean norm
$||\mathbf{x}||^2_2=\mathbf{x}^T\mathbf{x}=x_1^2+\cdots+x_n^2$. We can
model the squared Euclidean norm or sum-of-squared constraint
$||\mathbf{x}||_2^2\leq c$ using a rotated quadratic cone:
$$(c,\frac{1}{2},\mathbf{x})\in\mathcal{Q}_r^{n+2}$$

\subsection{Quadratic Form}
Let $\mathbf{x} \in \mathbb{R}^n$ and $\mathbf{Q}\in S^n_+$ ie a symmetric
positive semidefinite matrix. We can model a quadratic form constraint
$\frac{1}{2}\mathbf{x}^T\mathbf{Q}\mathbf{x}\leq c$ using either a
quadratic cone or a rotated quadratic cone. Observe that there exists
a (non unique) matrix $\mathbf{G}\in\mathbb{R}^{n \times k}$ such that
$\mathbf{Q} = \mathbf{G}\mathbf{G}^T$. Common ways of computing $\mathbf{G}$
are:
\begin{itemize}
\item{Cholesky decomposition:} $\mathbf{Q}=\mathbf{C}\mathbf{C}^T$, where
  $\mathbf{C}$ is a lower triangular matrix with nonnegative entries on
  the diagonal. With this decompostion we have
  $\mathbf{G}=\mathbf{C}\in\mathbf{R}^{n\times n}$.
\item{Eigenvalue decomposition:} $\mathbf{Q}=\mathbf{V}\mathbf{D}\mathbf{V}^T$,
  where the diagonal matrix $\mathbf{D}$ contains the (nonnegative)
  eigenvalues of $\mathbf{Q}$ and the unitary matriix $\mathbf{V}$ contains
  the corresponding eigenvectors in its columns. From this decomposition we
  have $\mathbf{G}=\mathbf{V}\mathbf{D}^{\frac{1}{2}}\in\mathbb{R}^{n\times n}$.
\item{Matrix square root:} $\mathbf{Q}=\mathbf{Q}^{1/2}\mathbf{Q}^{1/2}$, where
  $\mathbf{Q}^{1/2}$ is the symmetric positive semidefinite "square root"
  matrix of $\mathbf{Q}$. From this decomposition we have
  $\mathbf{G}=\mathbf{Q}^{1/2} \in \mathbb{R}^{n\times n}$.
\item{Factor model:} if $\mathbf{Q}$ is a covariance matrix of some date, then we can
  approximate the data series with the combination of $k \ll n$ common factors. We
  have the decomposition $\mathbf{Q}=\beta\mathbf{Q}_F\beta^T + \mathbf{D}$,
  where $\mathbf{Q}_F\in \mathbb{R}^{k\times k}$ is the covariance of the
  factors, $\beta\in\mathbb{R}^{n\times k}$ is the exposure of the data series
  to each factor, and $\mathbf{D}$ is diagonal. From this, by computing the
  Cholesky decomposition $\mathbf{Q}_F=\mathbf{F}\mathbf{F}^T$ we have
  $\mathbf{G}=[\beta\mathbf{F},\mathbf{D}^{1/2}]\in\mathbb{R}^{n\times(n+k)}$.
  The advantage of factor models is that $\mathbf{G}$ is very sparse and the
  factors have a direct financial interpretation.
\end{itemize}

After obtaining $\mathbf{G}$, we can write the quadratic form constraint as a
sum-of-squares $\frac{1}{2}\mathbf{x}^T\mathbf{}G^T\mathbf{x}\leq c$ which
is a squared Euclidean norm constraint
$\frac{1}{2}||\mathbf{G}^T\mathbf{x}||_2^2 \leq c$.
We can choose to model this using the rotated quadratic cone as
$$(c,1,\mathbf{G}^T\mathbf{x})\in \mathcal{Q}^{k+2},$$
or we can choose to model its square root using the quadratic cone as
$$(\sqrt{c}, \mathbf{G}^T\mathbf{x})\in\mathcal{Q}^{k+1}$$

Usually the quadratic cone is used to model 2-norm constraints while the
rotated quadratic cone is used to model quadratic functions.

\subsection{Power}
Let $x\in \mathbb{R}$ and $\alpha>1$, we can model a power constraint
$c \geq |x|^\alpha$ or equivalently $c^{1/\alpha}\geq|x|$ using a power
cone:
$$(c,1,x) \in \mathcal{P}_3^{1/\alpha,(\alpha-1)/\alpha}$$

\subsection{Exponential}
Let $x\in\mathbb{R}$ and $\alpha>1$, we can model an exponential
constraint $t\geq e^x$ using the exponential cone:
$$(t,1,x)\in K_\text{exp}$$

\subsection{Log-sum-exp}
Let $x_1,...,x_n \in \mathbb{R}$, we can model a log-sum-exp
constraint $t\geq \text{log}(\sum^n_{i=1}e^{x_i})$ with:
$$\sum^n_{i=1}u_i \leq 1,$$
$$(u_i,1,x_i-t) \in K_\text{exp}, i=1,...n$$

\subsection{Perspective of Function}
The perspective of a function $f(x)$ is defined as $sf(x/s)$ on $s>0$. For any
conic representation of $t\geq f(x)$ we can inspect $t\geq sf(x/s)$ by substituting
all constants $c$ with their homogenized counterpart $sc$.

\subsection{Perspective of log-sum-exp}
let $x_1,...,x_n\in\mathbb{R}$. We can model the perdpective of the log-sum-exp
constraint $t \geq s\text{log}(\sum^n_{i=1}e^{x_i/s})$ by applying:
$$\sum^n_{i=1}u_i \leq s,$$
$$(u_i,s,x_i-t) \in K_\text{exp}, i=1,...,n$$

\section{Traditional Quadratic Models}
How to convert traditional QO or QCQO problems into conic optimization form (much
more efficient computationally).

\subsection{Quadratic Optimization}
The standard form of the Quadratic Optimization problem is:
\begin{align}
  \begin{split}
    \text{minimize ~~~} \frac{1}{2}\mathbf{x}^T\mathbf{Q}\mathbf{x}+\mathbf{c}^T&\mathbf{x} \\
    \text{subject to ~~~~~~~~~~~~~~~ } \mathbf{A}&\mathbf{x}=\mathbf{b}, \\
    &\mathbf{x}\geq\mathbf{0} \\
  \end{split}
\end{align}

The matrix $\mathbf{Q} \in \mathbb{R}^{n\times n}$ must be symmetric positive semidefinite,
otherwise the objective function would not be convex.

Assuming the factorization $\mathbf{Q}=\mathbf{G}{G}^T$ with
$\mathbf{G}\in\mathbb{R}^{n\times k}$, we can reformulat the QO as a conic problem by applying
the previous sections methodology:
\begin{align}
  \begin{split}
    \text{minimize ~~~} t+\mathbf{c}^T\mathbf{x} \\
    \text{subject to ~~~~~~~~ } \mathbf{A}&\mathbf{x}=\mathbf{b}, \\
    &\mathbf{x}\geq\mathbf{0}, \\
    (t,1,\mathbf{G}^T&\mathbf{x}) \in \mathcal{Q}_r^{k+2}
  \end{split}
\end{align}

\subsection{Quadratically Constrained Quadratic Optimization}
Consider the quadratically constrained quadratic optimization (QCQO) problem of the form

\begin{align}
  \begin{split}
    \text{minimize ~~~} \frac{1}{2}\mathbf{x}^T\mathbf{Q}_0\mathbf{x}+\mathbf{c}_0^T&\mathbf{x} + a_0 \\
    \text{subject to ~ } \frac{1}{2}\mathbf{x}^T\mathbf{Q}_i\mathbf{x}+\mathbf{c}_i^T&\mathbf{x} + a_i \leq 0,~i=1,...,m. \\
  \end{split}
\end{align}

The matrices $\mathbf{Q}_i \in\mathbf{R}^{n\times n}, i = 0,...,m$ must all be symmetric positive
semidefinite, otherwise the optimization problem would not be convex.

Assuming the factorization $\mathbf{Q}=\mathbf{G}_i\mathbf{G}^T_i$ with
$\mathbf{G}_i\in\mathbb{R}^{n\times k_i}$, we can reformulate the problem
as a conic problem:

\begin{align}
  \begin{split}
    &\text{minimize ~} t_0+\mathbf{c}_0^T\mathbf{x}+_0 \\
    &\text{subject to } T_i + \mathbf{c}_i^T\mathbf{x} + a_i \leq 0,~ i=1,...m, \\
    &(t_i,1,\mathbf{G}^T_i\mathbf{x}) \in \mathcal{Q}_r^{k_i+2}, i=0,..., \\
  \end{split}
\end{align}

\subsection{Practical Benefits of Conic Model}
The key step is the model conversion is to transform quadratic terms $\mathbf{x}^T\mathbf{Q}\mathbf{x}$
using the factorization $\mathbf{Q}=\mathbf{G}\mathbf{G}^T$, where $\mathbf{G}\in\mathbb{R}^{n\times k}$.
Assuming $k\ll$, it results in the following benefits:
\begin{itemize}
\item{ The storage requirement $nk$ of $\mathbf{G}$ is much lower than the storage requirement
  $n^2/2$ of $\mathbf{Q}$.}
\item{The amount of work to evaluate $\mathbf{x}^T\mathbf{Q}\mathbf{x}$ is proportional to $n^2$
  whereas the work to evaluate $||\mathbf{G}^T\mathbf{x}||^2_2$ is proportional to $nk$ onlt.}
\item{ No need to numerically validate positive semidefiniteness of $\mathbf{Q}$. This would
  otherwise be difficult given that the presence of rounding errors can make $\mathbf{Q}$ indefinite.}
\item{Duality theory is much simpler for conic quadratic optimization.}
\end{itemize}

Ultimately, conic equivalents are not only as easy to solve as the original QP or QCQP problem, but
in mose cases also need less space and have faster solution times.


\end{document}
